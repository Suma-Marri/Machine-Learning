{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93790554",
   "metadata": {},
   "source": [
    "### Suma Marri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94c788",
   "metadata": {},
   "source": [
    "#### Problem 1: Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99614915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages to the jupyter notebook\n",
    "# Implement a Linear Regression model using both Normal Equation Method and SGD\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read and load the csv data file\n",
    "filename = \"Dataset/AMZN.csv\"\n",
    "data = read_csv ( filename )\n",
    "\n",
    "# Get the Adjusted Close Price\n",
    "data_select = data [['Adj Close']]\n",
    "\n",
    "# converting the dataset to a numpy array\n",
    "values = data_select.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d69b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "\"\"\"\n",
    "Frame a time series as a supervised learning dataset .\n",
    "Arguments :\n",
    "data : Sequence of observations as a list or NumPy array .\n",
    "n_in : Number of lag observations as input (X).\n",
    "n_out : Number of observations as output (y).\n",
    "dropnan : Boolean whether or not to drop rows with NaN values .\n",
    "Returns :\n",
    "Pandas DataFrame of series framed for supervised learning .\n",
    "\"\"\"\n",
    "\n",
    "def series_to_supervised ( data , n_in =1 , n_out =1 , dropnan = True ):\n",
    "    n_vars = 1 if type ( data ) is list else data . shape [1]\n",
    "    df = DataFrame ( data )\n",
    "    cols , names = list () , list ()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range ( n_in , 0 , -1 ):\n",
    "        cols . append ( df . shift ( i ) )\n",
    "        names += [('var %d(t-%d)' % ( j+1 , i ) ) for j in range ( n_vars )]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range (0 , n_out ):\n",
    "        cols.append ( df . shift (-i ) )\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % ( j+1 ) ) for j in range ( n_vars )]\n",
    "        else :\n",
    "            names += [('var%d(t+%d)' % ( j+1 , i ) ) for j in range ( n_vars )]\n",
    "    # put it all together\n",
    "    agg = concat ( cols , axis =1 )\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan :\n",
    "        agg.dropna( inplace = True )\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf004d",
   "metadata": {},
   "source": [
    "###### (a) \n",
    "Use the Python function named series_to_supervised() that takes a univariate or multivariate time series and frames it as a supervised learning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb0edcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var 1(t-10)</th>\n",
       "      <th>var 1(t-9)</th>\n",
       "      <th>var 1(t-8)</th>\n",
       "      <th>var 1(t-7)</th>\n",
       "      <th>var 1(t-6)</th>\n",
       "      <th>var 1(t-5)</th>\n",
       "      <th>var 1(t-4)</th>\n",
       "      <th>var 1(t-3)</th>\n",
       "      <th>var 1(t-2)</th>\n",
       "      <th>var 1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>1676.609985</td>\n",
       "      <td>1785.000000</td>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>1785.000000</td>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "      <td>1949.719971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "      <td>1949.719971</td>\n",
       "      <td>1907.699951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5748 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var 1(t-10)   var 1(t-9)   var 1(t-8)   var 1(t-7)   var 1(t-6)  \\\n",
       "10       1.958333     1.729167     1.708333     1.635417     1.427083   \n",
       "11       1.729167     1.708333     1.635417     1.427083     1.395833   \n",
       "12       1.708333     1.635417     1.427083     1.395833     1.500000   \n",
       "13       1.635417     1.427083     1.395833     1.500000     1.583333   \n",
       "14       1.427083     1.395833     1.500000     1.583333     1.531250   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5753  1676.609985  1785.000000  1689.150024  1807.839966  1830.000000   \n",
       "5754  1785.000000  1689.150024  1807.839966  1830.000000  1880.930054   \n",
       "5755  1689.150024  1807.839966  1830.000000  1880.930054  1846.089966   \n",
       "5756  1807.839966  1830.000000  1880.930054  1846.089966  1902.829956   \n",
       "5757  1830.000000  1880.930054  1846.089966  1902.829956  1940.099976   \n",
       "\n",
       "       var 1(t-5)   var 1(t-4)   var 1(t-3)   var 1(t-2)   var 1(t-1)  \\\n",
       "10       1.395833     1.500000     1.583333     1.531250     1.505208   \n",
       "11       1.500000     1.583333     1.531250     1.505208     1.500000   \n",
       "12       1.583333     1.531250     1.505208     1.500000     1.510417   \n",
       "13       1.531250     1.505208     1.500000     1.510417     1.479167   \n",
       "14       1.505208     1.500000     1.510417     1.479167     1.416667   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5753  1880.930054  1846.089966  1902.829956  1940.099976  1885.839966   \n",
       "5754  1846.089966  1902.829956  1940.099976  1885.839966  1955.489990   \n",
       "5755  1902.829956  1940.099976  1885.839966  1955.489990  1900.099976   \n",
       "5756  1940.099976  1885.839966  1955.489990  1900.099976  1963.949951   \n",
       "5757  1885.839966  1955.489990  1900.099976  1963.949951  1949.719971   \n",
       "\n",
       "          var1(t)  \n",
       "10       1.500000  \n",
       "11       1.510417  \n",
       "12       1.479167  \n",
       "13       1.416667  \n",
       "14       1.541667  \n",
       "...           ...  \n",
       "5753  1955.489990  \n",
       "5754  1900.099976  \n",
       "5755  1963.949951  \n",
       "5756  1949.719971  \n",
       "5757  1907.699951  \n",
       "\n",
       "[5748 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_to_supervised(data_select, n_in=10, n_out=1, dropnan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86bca2db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var 1(t-10)</th>\n",
       "      <th>var 1(t-9)</th>\n",
       "      <th>var 1(t-8)</th>\n",
       "      <th>var 1(t-7)</th>\n",
       "      <th>var 1(t-6)</th>\n",
       "      <th>var 1(t-5)</th>\n",
       "      <th>var 1(t-4)</th>\n",
       "      <th>var 1(t-3)</th>\n",
       "      <th>var 1(t-2)</th>\n",
       "      <th>var 1(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.958333</td>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.729167</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.708333</td>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.635417</td>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.427083</td>\n",
       "      <td>1.395833</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.583333</td>\n",
       "      <td>1.531250</td>\n",
       "      <td>1.505208</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.510417</td>\n",
       "      <td>1.479167</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>1.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>1676.609985</td>\n",
       "      <td>1785.000000</td>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>1785.000000</td>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>1689.150024</td>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>1807.839966</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "      <td>1949.719971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>1830.000000</td>\n",
       "      <td>1880.930054</td>\n",
       "      <td>1846.089966</td>\n",
       "      <td>1902.829956</td>\n",
       "      <td>1940.099976</td>\n",
       "      <td>1885.839966</td>\n",
       "      <td>1955.489990</td>\n",
       "      <td>1900.099976</td>\n",
       "      <td>1963.949951</td>\n",
       "      <td>1949.719971</td>\n",
       "      <td>1907.699951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5748 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      var 1(t-10)   var 1(t-9)   var 1(t-8)   var 1(t-7)   var 1(t-6)  \\\n",
       "10       1.958333     1.729167     1.708333     1.635417     1.427083   \n",
       "11       1.729167     1.708333     1.635417     1.427083     1.395833   \n",
       "12       1.708333     1.635417     1.427083     1.395833     1.500000   \n",
       "13       1.635417     1.427083     1.395833     1.500000     1.583333   \n",
       "14       1.427083     1.395833     1.500000     1.583333     1.531250   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5753  1676.609985  1785.000000  1689.150024  1807.839966  1830.000000   \n",
       "5754  1785.000000  1689.150024  1807.839966  1830.000000  1880.930054   \n",
       "5755  1689.150024  1807.839966  1830.000000  1880.930054  1846.089966   \n",
       "5756  1807.839966  1830.000000  1880.930054  1846.089966  1902.829956   \n",
       "5757  1830.000000  1880.930054  1846.089966  1902.829956  1940.099976   \n",
       "\n",
       "       var 1(t-5)   var 1(t-4)   var 1(t-3)   var 1(t-2)   var 1(t-1)  \\\n",
       "10       1.395833     1.500000     1.583333     1.531250     1.505208   \n",
       "11       1.500000     1.583333     1.531250     1.505208     1.500000   \n",
       "12       1.583333     1.531250     1.505208     1.500000     1.510417   \n",
       "13       1.531250     1.505208     1.500000     1.510417     1.479167   \n",
       "14       1.505208     1.500000     1.510417     1.479167     1.416667   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5753  1880.930054  1846.089966  1902.829956  1940.099976  1885.839966   \n",
       "5754  1846.089966  1902.829956  1940.099976  1885.839966  1955.489990   \n",
       "5755  1902.829956  1940.099976  1885.839966  1955.489990  1900.099976   \n",
       "5756  1940.099976  1885.839966  1955.489990  1900.099976  1963.949951   \n",
       "5757  1885.839966  1955.489990  1900.099976  1963.949951  1949.719971   \n",
       "\n",
       "          var1(t)  \n",
       "10       1.500000  \n",
       "11       1.510417  \n",
       "12       1.479167  \n",
       "13       1.416667  \n",
       "14       1.541667  \n",
       "...           ...  \n",
       "5753  1955.489990  \n",
       "5754  1900.099976  \n",
       "5755  1963.949951  \n",
       "5756  1949.719971  \n",
       "5757  1907.699951  \n",
       "\n",
       "[5748 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised_data = series_to_supervised(data_select, n_in=10, n_out=1, dropnan=True)\n",
    "supervised_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5fc3d0",
   "metadata": {},
   "source": [
    "###### (b) \n",
    "Use MinMaxScaler to scale your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfa120c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "supervised_data = scaler.fit_transform(supervised_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004bb30",
   "metadata": {},
   "source": [
    "###### (c)\n",
    "Use the Normal Equation Method to find the linear regression coefficients (w). To perform this you may want to take the following steps first: Split your data to X and Y by taking the columns var1(t-10),...,var(t-1) as your 10 features in X, and take the last column var1(t) as your target (Y). Expand your matrix X with a bias vector of ones as the first column (to accomplish this, you may want to use the numpy operations np.ones , np.reshape and np.append). Use the train test split with ‘random state=1’ to split your data to 70% training, and 30% test data. Solve the Normal Equation Method in (2) to find the coefficients w."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4761efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = supervised_data[:,-1]\n",
    "X = supervised_data[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bac0d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5748, 10)\n",
      "(5748,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2944d215",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 12480 into shape (5758,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\SUMAMA~1\\AppData\\Local\\Temp/ipykernel_27400/2383693082.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalEquation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\SUMAMA~1\\AppData\\Local\\Temp/ipykernel_27400/2383693082.py\u001b[0m in \u001b[0;36mnormalEquation\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# dimensions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1248\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# I combine these two vectors together to get a (m, 2) matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    297\u001b[0m            [5, 6]])\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'reshape'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 12480 into shape (5758,1)"
     ]
    }
   ],
   "source": [
    "def normalEquation(X, Y):\n",
    "    m = int(np.size(data_select.iloc[:, -1]))\n",
    "\n",
    "    # This is the feature / parameter (2x2) vector that will\n",
    "    # contain my minimized values\n",
    "    theta = []\n",
    "\n",
    "    # I create a bias_vector to add to my newly created X vector\n",
    "    bias_vector = np.ones((m, 1))\n",
    "\n",
    "    # I need to reshape my original X(m,) vector so that I can\n",
    "    # manipulate it with my bias_vector; they need to share the same\n",
    "    # dimensions.\n",
    "    X = np.arange(12480).reshape(1248, 10)\n",
    "    X = np.reshape(X, (m, 1))\n",
    "\n",
    "    # I combine these two vectors together to get a (m, 2) matrix\n",
    "    X = np.append(bias_vector, X, axis=1)\n",
    "\n",
    "    # Normal Equation:\n",
    "    # theta = inv(X^T * X) * X^T * y\n",
    "\n",
    "    # For convenience I create a new, tranposed X matrix\n",
    "    X_transpose = np.transpose(X)\n",
    "\n",
    "    # Calculating theta\n",
    "    theta = np.linalg.inv(X_transpose.dot(X))\n",
    "    theta = theta.dot(X_transpose)\n",
    "    theta = theta.dot(y)\n",
    "\n",
    "    return theta\n",
    "\n",
    "p = normalEquation(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24126482",
   "metadata": {},
   "source": [
    "###### (d)\n",
    "Make a prediction on your test set using the linear regression function f(x) = wT x, and use both the mean square error and coefficient of determination R2 to measure the performance of your prediction model. For this use fucntions mean squared error and r2 score from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c4a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288befa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c13d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3171dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b17877e6",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "Create a Perceptron model with an optimal value of hyperparameter α (learning rate of SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c85cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages to the Jupyter notebook\n",
    "# Implement a Perceptron algorithm with an optimal value of learning rate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# read and load the csv data file\n",
    "filename = \"Dataset/sonar.all-data.csv\"\n",
    "dataframe = read_csv (filename)\n",
    "\n",
    "# converting the dataset to a numpy array\n",
    "array = dataframe . values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array [:,:-1]\n",
    "Y = array [:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86635f2",
   "metadata": {},
   "source": [
    "###### (a)\n",
    "Split your data into train and test portions with ‘test size = 0.3’ and ’random state = 3’ . Define your learning model to be Perceptron. Use RepeatedStratifiedKFold with ‘n splits=10’, ‘n repeats=5’, and ‘random state=1’ as your model evaluation method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e2b3167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Perceptron()\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=3)\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d77d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = Perceptron()\n",
    "# define model evaluation method\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e05556",
   "metadata": {},
   "source": [
    "###### (b)\n",
    "Use GridSearchCV to perform a gird search on the parameter of Perceptron algorithm (learning rate α in SGD), consider values for α as [0.0001, 0.001, 0.01, 0.1]. For your GridSearch, use data only from your training sets (X-train, Y_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e018ec6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define grid\n",
    "grid = dict()\n",
    "grid['alpha'] = [0.0001, 0.001, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4c7e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61cfe9e",
   "metadata": {},
   "source": [
    "###### (c)\n",
    "Report the best score and the best value of the parameter in your search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdca053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.664\n",
      "Config: {'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# summarize\n",
    "print('Mean Accuracy: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006e5be6",
   "metadata": {},
   "source": [
    "###### (d)\n",
    "Create a Perceptron model which takes as an argument the best value of parameter you found in the previous step, and use this model to make predictions on your test set; Report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e67e2625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7172413793103448"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(alpha=0.0001)\n",
    "results = clf.fit(X_train, Y_train)\n",
    "results.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5bcc1",
   "metadata": {},
   "source": [
    "If you see in part c, we used the attribute best_score_ on GridSearchCV to find the mean accuracy or the mean cross-validated score of the best estimator, which was about 0.664. We also used the best_params_ attribute to find the \n",
    "parameter setting that gave the best results on the hold out data, which happened to be 0.0001 in this example. \n",
    "Then, when we used the score() method on the Perceptron model. The score() method returns the mean accuracy on the given test data and labels. We got a mean accuracy of about 0.712, which is higher than the mean accuracy of the GridSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2dbc8",
   "metadata": {},
   "source": [
    "#### Problem 3: Create a KNN model with an optimal value of hyperparameter K (the number of nearest neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48756769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages to the Jupyter notebook\n",
    "# Create a KNN model with the best parameter K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn . model_selection import train_test_split\n",
    "from sklearn . metrics import accuracy_score\n",
    "from sklearn . neighbors import KNeighborsClassifier\n",
    "\n",
    "# read and load the csv data file\n",
    "filename = \"Dataset/sonar.all-data.csv\"\n",
    "dataframe = read_csv (filename)\n",
    "\n",
    "# converting the dataset to a numpy array\n",
    "array = dataframe . values\n",
    "\n",
    "# separate array into input and output components\n",
    "X = array [:,:-1]\n",
    "Y = array [:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c62f5b",
   "metadata": {},
   "source": [
    "###### (a) \n",
    "Split the data into train and test sets with 'test_size = 0.3', and 'random_state = 5'. Create a KNN model with parameter 'n_neighbor' varying from 1 to 30 (see the code from Lab Session 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ded47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a991da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for k in range(1,30):\n",
    "  knn = KNeighborsClassifier(n_neighbors=k)\n",
    "  knn.fit(X_train, Y_train)\n",
    "  y_pred = knn.predict(X_test)\n",
    "  scores[k] = accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1186642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7777777777777778,\n",
       " 2: 0.7142857142857143,\n",
       " 3: 0.7301587301587301,\n",
       " 4: 0.7142857142857143,\n",
       " 5: 0.746031746031746,\n",
       " 6: 0.746031746031746,\n",
       " 7: 0.6507936507936508,\n",
       " 8: 0.6349206349206349,\n",
       " 9: 0.6666666666666666,\n",
       " 10: 0.6666666666666666,\n",
       " 11: 0.6825396825396826,\n",
       " 12: 0.6507936507936508,\n",
       " 13: 0.6666666666666666,\n",
       " 14: 0.6507936507936508,\n",
       " 15: 0.6825396825396826,\n",
       " 16: 0.6666666666666666,\n",
       " 17: 0.6507936507936508,\n",
       " 18: 0.6666666666666666,\n",
       " 19: 0.6507936507936508,\n",
       " 20: 0.7142857142857143,\n",
       " 21: 0.6825396825396826,\n",
       " 22: 0.6825396825396826,\n",
       " 23: 0.6984126984126984,\n",
       " 24: 0.6825396825396826,\n",
       " 25: 0.6825396825396826,\n",
       " 26: 0.6825396825396826,\n",
       " 27: 0.6666666666666666,\n",
       " 28: 0.6984126984126984,\n",
       " 29: 0.7142857142857143}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d57f1",
   "metadata": {},
   "source": [
    "###### (b)\n",
    "Plot the accuracy of the KNN model in terms of the number of nearest neighbor k varying from 1 to 30. Choose and report the best value for k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71bab02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cb380242b0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(scores.keys()),list(scores.values()),marker=\"o\", markersize=2, markeredgecolor=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c875b8",
   "metadata": {},
   "source": [
    "After running the KNeighborsClassifier with diffrent number of neighbors (1 -30), we can see that the best value of k is 1. If you see the list of accuracy classification scores and the line graph, you can see that k=1 has the highest  accuracy. Then 5 and 6 would be the next best values for k. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b366c",
   "metadata": {},
   "source": [
    "###### (c)\n",
    "Create a new KNN model with the best values of nearest neighbors that you found in previous step, and perform prediction on your test set. Report the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "233d3b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13eccf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7777777777777778"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "score = accuracy_score(y_pred, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a4e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8344827586206897"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b406e63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "score = accuracy_score(y_pred, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08148576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275862068965517"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f0b1886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.746031746031746"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "score = accuracy_score(y_pred, Y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da963f9e",
   "metadata": {},
   "source": [
    "When I take the KNeighborsClassifier and use the score method, I get the mean accuracy of the data. However, I found this unreliable, because it is checking if it is an exact match of X_train to get high accuracy. That is why the accuracy_score(y_pred, Y_test) was a better test. I choosed the 3 highest accuracy's (k = 1, 5, & 6). k = 1 was the highest and 5/6 tied for 2nd. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa020221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
